{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Optimizing Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will build logistic regression models using \"Cell2Cell\", a telecom company churn prediction data set. You will build many variants, each one with a different value of the $C$ hyperparameter, which governs the amount of regularization used. Regularization is a process where we add a \"penalty\" to the original log loss function. This penalty is a function of the magnitudes of the weights learned in the Logistic Regression. The following shows the regularized log loss using what is called \"L2\" regularization.<br><br> \n",
    "\n",
    "<center>$Regularized \\ LogLoss = -\\frac{1}{n} \\sum\\limits_{i=1}^n (y_i*log(p_i)+(1-y_i)*log(1-p_i))+\\frac{1}{C} \\sum\\limits_{j=1}^m W_j^2$</center><br><br>\n",
    "\n",
    "\n",
    "\n",
    "With L2 regularization, the penalty is the sum of the squares of the weights scaled by a constant $1/C$. When the hyperparameter $C$ is large, we reduce the weight of the penalty, which results in less regularization. You will build Logistic regressions with different values of $C$ and will check how this impacts the log loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will implement the following steps:\n",
    "\n",
    "1. Load the \"cell2celltrain\" data set.\n",
    "2. Create unlabeled examples containing numerical features only.\n",
    "3. Split the data into training and test data sets.\n",
    "4. Fit a Logistic Regression classifier using scikit-learn and evaluate the log loss and accuracy of the predictions.\n",
    "5. Fit multiple Logistic Regression classifiers with different values of the regularization hyperparameter $C$ and plot the resulting log loss and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Load the Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with the \"cell2celltrain\" data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not remove or edit the line below:\n",
    "filename = os.path.join(os.getcwd(), \"data\", \"cell2celltrain.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Load the data and save it to DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Churn</th>\n",
       "      <th>ServiceArea</th>\n",
       "      <th>ChildrenInHH</th>\n",
       "      <th>HandsetRefurbished</th>\n",
       "      <th>HandsetWebCapable</th>\n",
       "      <th>TruckOwner</th>\n",
       "      <th>RVOwner</th>\n",
       "      <th>HomeownershipKnown</th>\n",
       "      <th>BuysViaMailOrder</th>\n",
       "      <th>...</th>\n",
       "      <th>HandsetModels</th>\n",
       "      <th>CurrentEquipmentDays</th>\n",
       "      <th>AgeHH1</th>\n",
       "      <th>AgeHH2</th>\n",
       "      <th>RetentionCalls</th>\n",
       "      <th>RetentionOffersAccepted</th>\n",
       "      <th>ReferralsMadeBySubscriber</th>\n",
       "      <th>IncomeGroup</th>\n",
       "      <th>AdjustmentsToCreditRating</th>\n",
       "      <th>HandsetPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000002</td>\n",
       "      <td>True</td>\n",
       "      <td>SEAPOR503</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487071</td>\n",
       "      <td>-0.077013</td>\n",
       "      <td>1.387766</td>\n",
       "      <td>-0.883541</td>\n",
       "      <td>4.662897</td>\n",
       "      <td>-0.1283</td>\n",
       "      <td>-0.169283</td>\n",
       "      <td>-0.103411</td>\n",
       "      <td>-0.140707</td>\n",
       "      <td>-0.864858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000010</td>\n",
       "      <td>True</td>\n",
       "      <td>PITHOM412</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.616775</td>\n",
       "      <td>3.019920</td>\n",
       "      <td>0.392039</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>-0.180167</td>\n",
       "      <td>-0.1283</td>\n",
       "      <td>-0.169283</td>\n",
       "      <td>0.215243</td>\n",
       "      <td>-0.140707</td>\n",
       "      <td>-0.864858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000014</td>\n",
       "      <td>False</td>\n",
       "      <td>MILMIL414</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.616775</td>\n",
       "      <td>3.019920</td>\n",
       "      <td>-0.241605</td>\n",
       "      <td>0.202910</td>\n",
       "      <td>-0.180167</td>\n",
       "      <td>-0.1283</td>\n",
       "      <td>-0.169283</td>\n",
       "      <td>0.533896</td>\n",
       "      <td>-0.140707</td>\n",
       "      <td>-0.368174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000022</td>\n",
       "      <td>False</td>\n",
       "      <td>PITHOM412</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2.694763</td>\n",
       "      <td>0.305179</td>\n",
       "      <td>-0.060564</td>\n",
       "      <td>-0.883541</td>\n",
       "      <td>-0.180167</td>\n",
       "      <td>-0.1283</td>\n",
       "      <td>-0.169283</td>\n",
       "      <td>0.533896</td>\n",
       "      <td>-0.140707</td>\n",
       "      <td>-1.195980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000026</td>\n",
       "      <td>True</td>\n",
       "      <td>OKCTUL918</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1.590917</td>\n",
       "      <td>1.857585</td>\n",
       "      <td>0.663601</td>\n",
       "      <td>1.372934</td>\n",
       "      <td>-0.180167</td>\n",
       "      <td>-0.1283</td>\n",
       "      <td>-0.169283</td>\n",
       "      <td>1.489856</td>\n",
       "      <td>2.469282</td>\n",
       "      <td>-1.195980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  Churn ServiceArea  ChildrenInHH  HandsetRefurbished  \\\n",
       "0     3000002   True   SEAPOR503         False               False   \n",
       "1     3000010   True   PITHOM412          True               False   \n",
       "2     3000014  False   MILMIL414          True               False   \n",
       "3     3000022  False   PITHOM412         False               False   \n",
       "4     3000026   True   OKCTUL918         False               False   \n",
       "\n",
       "   HandsetWebCapable  TruckOwner  RVOwner  HomeownershipKnown  \\\n",
       "0               True       False    False                True   \n",
       "1              False       False    False                True   \n",
       "2              False       False    False               False   \n",
       "3               True       False    False                True   \n",
       "4              False       False    False                True   \n",
       "\n",
       "   BuysViaMailOrder  ...  HandsetModels  CurrentEquipmentDays    AgeHH1  \\\n",
       "0              True  ...       0.487071             -0.077013  1.387766   \n",
       "1              True  ...      -0.616775              3.019920  0.392039   \n",
       "2             False  ...      -0.616775              3.019920 -0.241605   \n",
       "3              True  ...       2.694763              0.305179 -0.060564   \n",
       "4              True  ...       1.590917              1.857585  0.663601   \n",
       "\n",
       "     AgeHH2  RetentionCalls  RetentionOffersAccepted  \\\n",
       "0 -0.883541        4.662897                  -0.1283   \n",
       "1  0.871495       -0.180167                  -0.1283   \n",
       "2  0.202910       -0.180167                  -0.1283   \n",
       "3 -0.883541       -0.180167                  -0.1283   \n",
       "4  1.372934       -0.180167                  -0.1283   \n",
       "\n",
       "   ReferralsMadeBySubscriber  IncomeGroup  AdjustmentsToCreditRating  \\\n",
       "0                  -0.169283    -0.103411                  -0.140707   \n",
       "1                  -0.169283     0.215243                  -0.140707   \n",
       "2                  -0.169283     0.533896                  -0.140707   \n",
       "3                  -0.169283     0.533896                  -0.140707   \n",
       "4                  -0.169283     1.489856                   2.469282   \n",
       "\n",
       "  HandsetPrice  \n",
       "0    -0.864858  \n",
       "1    -0.864858  \n",
       "2    -0.368174  \n",
       "3    -1.195980  \n",
       "4    -1.195980  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "df = pd.read_csv(filename)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Create Labeled Examples from the Data Set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement a Logistic Regression model, we must use only the numeric columns. \n",
    "\n",
    "\n",
    "<b>Task</b>: Use the Pandas DataFrame <code>select_dtypes()</code> method to obtain all of names of columns that have a dtype of \"float64.\" Save the result to a list named `feature_list`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MonthlyRevenue',\n",
       " 'MonthlyMinutes',\n",
       " 'TotalRecurringCharge',\n",
       " 'DirectorAssistedCalls',\n",
       " 'OverageMinutes',\n",
       " 'RoamingCalls',\n",
       " 'PercChangeMinutes',\n",
       " 'PercChangeRevenues',\n",
       " 'DroppedCalls',\n",
       " 'BlockedCalls',\n",
       " 'UnansweredCalls',\n",
       " 'CustomerCareCalls',\n",
       " 'ThreewayCalls',\n",
       " 'ReceivedCalls',\n",
       " 'OutboundCalls',\n",
       " 'InboundCalls',\n",
       " 'PeakCallsInOut',\n",
       " 'OffPeakCallsInOut',\n",
       " 'DroppedBlockedCalls',\n",
       " 'CallForwardingCalls',\n",
       " 'CallWaitingCalls',\n",
       " 'MonthsInService',\n",
       " 'UniqueSubs',\n",
       " 'ActiveSubs',\n",
       " 'Handsets',\n",
       " 'HandsetModels',\n",
       " 'CurrentEquipmentDays',\n",
       " 'AgeHH1',\n",
       " 'AgeHH2',\n",
       " 'RetentionCalls',\n",
       " 'RetentionOffersAccepted',\n",
       " 'ReferralsMadeBySubscriber',\n",
       " 'IncomeGroup',\n",
       " 'AdjustmentsToCreditRating',\n",
       " 'HandsetPrice']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "feature_list = list(df.select_dtypes('float64'))\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: Create labeled examples from DataFrame `df`.\n",
    "\n",
    "In the code cell below carry out the following steps:\n",
    "\n",
    "* Get the `Churn` column from DataFrame `df` and assign it to the variable `y`. This will be our label. The label will be either True or False.\n",
    "* Get the columns listed in `feature_list`from DataFrame `df` and assign them to the variable `X`. These will be our features. \n",
    "\n",
    "You should have 51047 labeled examples. Each example contains 35 features and one label (`Churn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 51047\n",
      "\n",
      "Number of Features:35\n",
      "['MonthlyRevenue', 'MonthlyMinutes', 'TotalRecurringCharge', 'DirectorAssistedCalls', 'OverageMinutes', 'RoamingCalls', 'PercChangeMinutes', 'PercChangeRevenues', 'DroppedCalls', 'BlockedCalls', 'UnansweredCalls', 'CustomerCareCalls', 'ThreewayCalls', 'ReceivedCalls', 'OutboundCalls', 'InboundCalls', 'PeakCallsInOut', 'OffPeakCallsInOut', 'DroppedBlockedCalls', 'CallForwardingCalls', 'CallWaitingCalls', 'MonthsInService', 'UniqueSubs', 'ActiveSubs', 'Handsets', 'HandsetModels', 'CurrentEquipmentDays', 'AgeHH1', 'AgeHH2', 'RetentionCalls', 'RetentionOffersAccepted', 'ReferralsMadeBySubscriber', 'IncomeGroup', 'AdjustmentsToCreditRating', 'HandsetPrice']\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "y = df['Churn']\n",
    "X = df[feature_list]\n",
    "\n",
    "\n",
    "print(\"Number of examples: \" + str(X.shape[0]))\n",
    "print(\"\\nNumber of Features:\" + str(X.shape[1]))\n",
    "print(str(list(X.columns)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Create Training and Test Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: In the code cell below create training and test data sets out of the labeled examples. \n",
    "\n",
    "1. Use scikit-learn's `train_test_split()` method to create the data sets.\n",
    "\n",
    "2. Specify:\n",
    "    * A test set that is 33 percent (.33) of the size of the data set.\n",
    "    * A seed value of '1234'. \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the dimensions of the training and test data sets are what you expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34201, 35)\n",
      "(16846, 35)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Fit a Logistic Regression Classifier and Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below contains a shell of a function named `train_test_LR()`. This function will train a Logistic Regression model on the training data, test the resulting model on the test data, and compute and return (1) the log loss of the resulting probability predictions on the test data and (2) the accuracy score of the resulting predicted class labels on the test data. \n",
    "\n",
    "Inspect the function definition `train_test_LR(X_train, X_test, y_train, y_test, c=1)`. The function expects the test and train datasets as well as a value for hyperparameter $C$. Note that we supplied the value of 1 for $C$ by default.\n",
    "\n",
    "You will use the scikit-learn ```LogisticRegression``` class. Use `LogisticRegression()` to create a model object, and assign the result to the variable ```model```. You will provide the arguments `C=c`.\n",
    "\n",
    "<b>Task:</b> Complete the function to make it work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_LR(X_train, y_train, X_test, y_test, c=1):\n",
    "    '''\n",
    "    Fit a Linear Regression classifier to the training data X_train, y_train.\n",
    "    Return the loss and accuracy of resulting predictions on the test set.\n",
    "    Parameters:\n",
    "        C = Factor that controls how much regularization is applied to the model.\n",
    "    '''\n",
    "     # 1. Create the  scikit-learn LogisticRegression model object below and assign to variable 'model'\n",
    "      # YOUR CODE HERE\n",
    "    model = LogisticRegression(C = c)\n",
    "    \n",
    "  \n",
    "    # 2. Fit the model to the training data below\n",
    "     # YOUR CODE HERE\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    # 3. Make predictions on the test data using the predict_proba() method and assign the result to the \n",
    "    # variable 'probability_predictions' below\n",
    "     # YOUR CODE HERE\n",
    "    probability_predictions = model.predict_proba(X_test)\n",
    "  \n",
    "    # 4. Compute the log loss on 'probability_predictions' and save the result to the variable 'l_loss' below\n",
    "     # YOUR CODE HERE\n",
    "    l_loss = log_loss(y_test, probability_predictions)\n",
    "        \n",
    "        \n",
    "    # 5. Make predictions on the test data using the predict() method and assign the result to the \n",
    "    # variable 'class_label_predictions' below\n",
    "     # YOUR CODE HERE\n",
    "    class_label_predictions = model.predict(X_test)\n",
    "        \n",
    "        \n",
    "    # 6. Compute the accuracy score on 'class_label_predictions' and save the result to the variable 'acc_score' below\n",
    "    # YOUR CODE HERE\n",
    "    acc_score = accuracy_score(y_test, class_label_predictions)\n",
    "    \n",
    "    return l_loss, acc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Train a Model and Analyze the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below uses your function `train_test_LR()` to train one Logistic Regression classifier with the default value of hyperparameter C (`c=1`) and evaluates the model's predictions on the test data. Run the code cell and inspect the resulting loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.5878612157234173\n",
      "Accuracy: 0.7097827377418972\n"
     ]
    }
   ],
   "source": [
    "loss, acc = train_test_LR(X_train, y_train, X_test, y_test)\n",
    "print('Log loss: ' + str(loss))\n",
    "print('Accuracy: ' + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5. Train on Different Hyperparameter Values and Analyze the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will adjust the $C$ Regularization hyperparameter to check its impact on the model's log loss. In the scikit-learn ``LogisticRegression`` class documentation, parameter `C` stands for the inverse of regularization strength. Smaller values specify stronger regularization.<br>\n",
    "\n",
    "The code cell below creates a list `cs` of twenty values of $C$.  Every item in the list has a value $10^e$ for every integer $e$ in the output of `range(-10,10)`. Run the code cell below and inspect the different values of $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1e-10,\n",
       " 1e-09,\n",
       " 1e-08,\n",
       " 1e-07,\n",
       " 1e-06,\n",
       " 1e-05,\n",
       " 0.0001,\n",
       " 0.001,\n",
       " 0.01,\n",
       " 0.1,\n",
       " 1,\n",
       " 10,\n",
       " 100,\n",
       " 1000,\n",
       " 10000,\n",
       " 100000,\n",
       " 1000000,\n",
       " 10000000,\n",
       " 100000000,\n",
       " 1000000000]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs = [10**i for i in range(-10,10)]\n",
    "cs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to train and evaluate a different Logistic Regression model for every value of $C$ in the list `cs`. \n",
    "\n",
    "<b>Task</b>: In the code cell below, follow these steps:\n",
    "\n",
    "1. Initialize an empty Python list called `ll_cs`. This is where we will store the log loss for every model.\n",
    "2. Initialize an empty Python list called `acc_cs`. This is where we will store the accuracy score for every model.\n",
    "2. Write a loop that iterates over list `cs`. Within the loop, do the following:\n",
    "3. Call your function `train_test_LR()` with the training and test data and with the current value of $C$.\n",
    "4. The function `train_test_LR()` returns two items. \n",
    "    1. Append the first item to the list `ll_cs`.\n",
    "    2. Append the second item to the list `acc_cs`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "ll_cs = []\n",
    "acc_cs = []\n",
    "for c in cs:\n",
    "    l_loss, acc_score = train_test_LR(X_train, y_train, X_test, y_test, c)\n",
    "    ll_cs.append(l_loss)\n",
    "    acc_cs.append(acc_cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets visualize the results. \n",
    "\n",
    "#### Plot Log Loss\n",
    "\n",
    "Execute the code below to plot the resulting log loss for every value of hyperparameter $C$. Take some time to study the code, which uses `seaborn` to build the main plot and `matplotlib` to customize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5)) \n",
    "\n",
    "ax = sns.barplot(x=cs, y=ll_cs)\n",
    "g = ax.set_xticklabels([f'10^{i}' for i in range(-10,10)])\n",
    "ax.set_xlabel('Regularization HyperParameter: C')\n",
    "ax.set_ylabel('Log Loss')\n",
    "ax.set_ylim([0.5, 0.62])\n",
    "g = plt.title('Log Loss Test Performance by Regularization Weight C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Analysis</b>: Which value of $C$ yields the best results, in terms of loss?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A C value of 10^-3 and higher yields the best results in terms of loss. Any value lower than 10^-3 seems to result in a higher log loss and anything higher than it results in a similar log loss than that of 10^-3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Accuracy\n",
    "\n",
    "Execute the code below below to plot the resulting accuracy for every value of hyperparameter $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "x = np.log10(cs)\n",
    "\n",
    "sns.lineplot(x=x, y=acc_cs, marker='o')\n",
    "\n",
    "plt.title(\"Accuracy Test Performance by Regularization Weight C'\")\n",
    "plt.xlabel(\"Regularization HyperParameter: C\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Analysis</b>: Which value of $C$ yields the best results, in terms of accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Double click this Markdown cell to make it editable, and record your findings here.>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
